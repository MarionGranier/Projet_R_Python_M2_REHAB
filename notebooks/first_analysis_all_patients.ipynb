{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First analysis\n",
    "Author: Marion Granier  \n",
    "Date: 2025-03-04 \n",
    "  \n",
    "This script uses part of Victor Fernando Lopes De Souza's script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the autoreload extension\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\Desktop\\Master REHAB\\M2\\Stage\\Projet R Python Denis Mottet\\Projet_R_Python_TEST STRUCURE\\notebooks\\functional_metrics.py:19: SyntaxWarning: invalid escape sequence '\\o'\n",
      "  \"\"\"\n",
      "c:\\Users\\Lenovo\\Desktop\\Master REHAB\\M2\\Stage\\Projet R Python Denis Mottet\\Projet_R_Python_TEST STRUCURE\\notebooks\\functional_metrics.py:39: SyntaxWarning: invalid escape sequence '\\o'\n",
      "  \"\"\"\n",
      "c:\\Users\\Lenovo\\Desktop\\Master REHAB\\M2\\Stage\\Projet R Python Denis Mottet\\Projet_R_Python_TEST STRUCURE\\notebooks\\functional_metrics.py:45: SyntaxWarning: invalid escape sequence '\\l'\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "# Set extension to autoreload all modules every time before executing the Python code\n",
    "%autoreload 2\n",
    "\n",
    "# Importing the necessary libraries\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['agg.path.chunksize'] = 10000\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import handle_data, functional_metrics\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if all files are present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C1P20', 'C1P30', 'C1P31', 'C1P32', 'C1P33']\n",
      "Fichiers manquants dans C1P20_M1 : right.csv\n",
      "Dossier manquant : C1P20_M2\n",
      "Dossier manquant : C1P20_M3\n",
      "Dossier manquant : C1P20_M4\n",
      "Dossier manquant : C1P20_M5\n",
      "Dossier manquant : C1P20_M6\n",
      "Dossier manquant : C1P30_M1\n",
      "Dossier manquant : C1P30_M2\n",
      "Dossier manquant : C1P30_M3\n",
      "Dossier manquant : C1P30_M4\n",
      "Dossier manquant : C1P30_M5\n",
      "Dossier manquant : C1P30_M6\n",
      "Dossier manquant : C1P31_M1\n",
      "Dossier manquant : C1P31_M2\n",
      "Dossier manquant : C1P31_M3\n",
      "Dossier manquant : C1P31_M4\n",
      "Dossier manquant : C1P31_M5\n",
      "Dossier manquant : C1P31_M6\n",
      "Dossier manquant : C1P32_M1\n",
      "Dossier manquant : C1P32_M2\n",
      "Dossier manquant : C1P32_M3\n",
      "Dossier manquant : C1P32_M4\n",
      "Dossier manquant : C1P32_M5\n",
      "Dossier manquant : C1P32_M6\n",
      "Dossier manquant : C1P33_M1\n",
      "Dossier manquant : C1P33_M2\n",
      "Dossier manquant : C1P33_M3\n",
      "Dossier manquant : C1P33_M4\n",
      "Dossier manquant : C1P33_M5\n",
      "Dossier manquant : C1P33_M6\n"
     ]
    }
   ],
   "source": [
    "# Definition of the base path and the list of patients\n",
    "base_path = \"../data/data_actimetry_copy\"\n",
    "participants_info = pd.read_csv('../data/participants_1.csv', sep=';')\n",
    "patients = participants_info['folder_name'].str.split('_M').str[0].tolist()\n",
    "# patients = [\"C1P20\", \"C1P30\", \"C1P31\", \"C1P32\", \"C1P33\"]\n",
    "print(patients)\n",
    "months = [f\"M{i}\" for i in range(1, 7)]  # M1 à M6\n",
    "\n",
    "# Function to check if the files are present\n",
    "def check_files():\n",
    "    \"\"\"\n",
    "    Check if the files are present in the base path for each patient and each month.\n",
    "    \"\"\"\n",
    "    for patient in patients:\n",
    "        for month in months:\n",
    "            folder_name = f\"{patient}_{month}\"\n",
    "            folder_path = os.path.join(base_path, folder_name)\n",
    "            \n",
    "            if not os.path.exists(folder_path):\n",
    "                print(f\"Missing file: {folder_name}\")\n",
    "                continue\n",
    "            \n",
    "            left_file = os.path.join(folder_path, \"left.csv\")\n",
    "            right_file = os.path.join(folder_path, \"right.csv\")\n",
    "            \n",
    "            missing_files = []\n",
    "            if not os.path.isfile(left_file):\n",
    "                missing_files.append(\"left.csv\")\n",
    "            if not os.path.isfile(right_file):\n",
    "                missing_files.append(\"right.csv\")\n",
    "            \n",
    "            if missing_files:\n",
    "                print(f\"***** Missing files in {folder_name} : {', '.join(missing_files)} *****\")\n",
    "            else:\n",
    "                print(f\"All files are present in {folder_name}.\")\n",
    "\n",
    "# Check if the files are present\n",
    "check_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First analysis for a single patient\n",
    "\n",
    "### Enter the data information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patient's code (CXPXX)\n",
    "ID = \"C0P00\"\n",
    "\n",
    "# Number of the record (X in range of 1 to 6)\n",
    "month = \"1\"\n",
    "\n",
    "# Resampling\n",
    "resampling_freq = 50 # Hz\n",
    "\n",
    "# Low pass filter\n",
    "filter_butter_cutoff = 1 # Hz\n",
    "\n",
    "# Windowing\n",
    "seconds_per_window = 0.5 # s\n",
    "\n",
    "# To calculate the jerk ratio we ignore the moments where one arm is not moving\n",
    "treshold_removal_JR = 0.01 # m/s^3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FileName = ID + \"_M\" + month\n",
    "FileName\n",
    "\n",
    "# Load the data\n",
    "time_index, acceleration_xyzn, is_patient, FM = handle_data.extract_data(FileName, filter_butter_cutoff=filter_butter_cutoff, resampling_freq=resampling_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12959783, 2, 4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acceleration_xyzn.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_index_values = (time_index.values - np.datetime64('1970-01-01T00:00:00')) / np.timedelta64(1, 's')\n",
    "windows_small, time_indexes_small = handle_data.partition(acceleration_xyzn, time_index_values, seconds_per_window=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get jerk\n",
    "# jerk = functional_metrics.get_jerk(acceleration_xyzn, time_index_values)\n",
    "# get jerk ratio\n",
    "# jerk_ratio = functional_metrics.get_jerk_ratio(jerk, treshold_removal=treshold_removal_JR)\n",
    "# get jerk ratio mean\n",
    "# jerk_ratio_mean = np.mean(jerk_ratio)\n",
    "\n",
    "# get angles\n",
    "alphas = functional_metrics.get_alphas(windows_small[:, :, :, 1], windows_small[:, :, :, 3])\n",
    "\n",
    "# get if window contains a functional movement for different (symmetric) angle thresholds (10, 20, ..., 80)\n",
    "test_range = range(10, 90, 10)\n",
    "is_functional = {i : functional_metrics.test_functional(alphas=alphas, treshold_symregion_degrees=i, treshold_amp_degrees=30) for i in test_range}\n",
    "\n",
    "# get functional use counts\n",
    "functional_uses = {i : is_functional[i].sum(axis=0) for i in test_range}\n",
    "functional_uses_df = pd.DataFrame(functional_uses).T\n",
    "functional_uses_df.columns = ['non_paretic', 'paretic']\n",
    "\n",
    "# get use hours (considering 30 degrees as threshold)\n",
    "use_hours = functional_metrics.get_use_hours(is_functional[30], time_indexes_small)\n",
    "use_hours\n",
    "# get use hours ratio\n",
    "use_hours_ratio = functional_metrics.get_ratio(use_hours[0], use_hours[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ID month  day  FuncUse_non_paretic_day  FuncUse_paretic_day  \\\n",
      "0  C0P00     1    1                    435.0                368.0   \n",
      "1  C0P00     1    2                    288.0                298.0   \n",
      "2  C0P00     1    3                    381.0                382.0   \n",
      "\n",
      "   FuncUseRatio_day  \n",
      "0          0.458281  \n",
      "1          0.508532  \n",
      "2          0.500655  \n"
     ]
    }
   ],
   "source": [
    "def get_functional_count_per_day(is_functional, time_indexes):\n",
    "    # get first element of each window\n",
    "    start = time_indexes[:, 0]\n",
    "    \n",
    "    # get differences\n",
    "    delta_windowing = np.diff(start).mean()\n",
    "    \n",
    "    # get the second when each window starts\n",
    "    time_after_beginning = np.cumsum(delta_windowing * np.ones(start.shape[0]))\n",
    "    second_of_measurement = np.floor(time_after_beginning).astype(int)\n",
    "\n",
    "    # convert seconds to days\n",
    "    day_of_measurement = second_of_measurement // (24 * 3600)\n",
    "\n",
    "    # one row per day, one column per arm\n",
    "    functional_count_day = np.zeros((day_of_measurement[-1] + 1, is_functional.shape[1]))\n",
    "    \n",
    "    # the functional count in each day is the number of functional movements that started in that day\n",
    "    for i in range(is_functional.shape[0]):\n",
    "        for j in range(is_functional.shape[1]):\n",
    "            functional_count_day[day_of_measurement[i], j] += is_functional[i, j]\n",
    "\n",
    "    return functional_count_day\n",
    "\n",
    "# Use the new function to get functional count per day\n",
    "functional_count_per_day = get_functional_count_per_day(is_functional[30], time_indexes_small)\n",
    "functional_count_per_day\n",
    "functional_uses_per_day_df = pd.DataFrame(functional_count_per_day)\n",
    "\n",
    "# add a column for the month in the first column\n",
    "functional_uses_per_day_df.insert(0, 'ID', ID)\n",
    "functional_uses_per_day_df.insert(1, 'month', month)\n",
    "functional_uses_per_day_df.insert(2, 'day', range(1, functional_uses_per_day_df.shape[0] + 1))\n",
    "\n",
    "functional_uses_per_day_df.columns = ['ID', 'month', 'day', 'FuncUse_non_paretic_day', 'FuncUse_paretic_day']\n",
    "\n",
    "functional_uses_per_day_df['FuncUseRatio_day'] = functional_uses_per_day_df['FuncUse_paretic_day'] / (functional_uses_per_day_df['FuncUse_paretic_day'] + functional_uses_per_day_df['FuncUse_non_paretic_day'])\n",
    "\n",
    "print(functional_uses_per_day_df)\n",
    "\n",
    "# save the results per day\n",
    "functional_uses_per_day_df.to_csv('../results/results_FuncUsePerDay_' + ID + '_M' + month + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make the report for the patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe with the results\n",
    "results_global = pd.DataFrame({'month' : month,\n",
    "                        'FuncUse_non_paretic_month' : functional_uses_df.iloc[2, 0],\n",
    "                        'FuncUse_paretic_month' : functional_uses_df.iloc[2, 1],  \n",
    "                        'FuncUserRatio_month' : functional_uses_df.iloc[2, 1] / (functional_uses_df.iloc[2, 1] + functional_uses_df.iloc[2, 0]),\n",
    "                        'UseHours_non_paretic_month' : use_hours[0],\n",
    "                        'UseHours_paretic_month' : use_hours[1],\n",
    "                        'UseHoursRatio_month' : use_hours_ratio / 2}, index=[ID])\n",
    "results_global\n",
    "\n",
    "# save the results per month\n",
    "results_global.to_csv('../results/results_' + ID + '_M' + month + '.csv', index_label=\"ID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make the global report of all patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Added results_C0P00_M1.csv to ../results/dataOut4.csv.\n",
      "✅ Added results_C0P00_M2.csv to ../results/dataOut4.csv.\n",
      "✅ Merging process completed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Define the folder path and the output file\n",
    "folder_path = '../results/'\n",
    "output_file = os.path.join(folder_path, 'all_global_results.csv')\n",
    "\n",
    "# Identify the pattern of the files\n",
    "file_pattern = re.compile(r'results_C(\\w+)_M(\\d+)\\.csv')\n",
    "\n",
    "# Recover the list of files\n",
    "csv_files = [f for f in os.listdir(folder_path) if file_pattern.match(f)]\n",
    "\n",
    "# Sort the files by patient ID and month\n",
    "csv_files.sort(key=lambda x: (file_pattern.match(x).group(1), int(file_pattern.match(x).group(2))))\n",
    "\n",
    "# Load the first file to get the columns\n",
    "first_file = os.path.join(folder_path, csv_files[0])\n",
    "df_example = pd.read_csv(first_file)\n",
    "columns = df_example.columns.tolist()\n",
    "\n",
    "# Load the global DataFrame if it exists\n",
    "if os.path.exists(output_file):\n",
    "    global_df = pd.read_csv(output_file)\n",
    "else:\n",
    "    global_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "# Traits each file\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "\n",
    "    try:\n",
    "        # read the file\n",
    "        df = pd.read_csv(file_path, skiprows=1, header=None, names=columns)\n",
    "        if df.empty:\n",
    "            print(f\"***** Warning: {file} is empty and will be skipped. *****\")\n",
    "            continue\n",
    "\n",
    "        # Recover the patient ID and month\n",
    "        match = file_pattern.match(file)\n",
    "        patient_id, month = match.groups()\n",
    "        month = int(month)\n",
    "\n",
    "        # Check if the data is already in the global\n",
    "        if not global_df.empty and ((global_df['ID'] == patient_id) & (global_df['month'] == month)).any():\n",
    "            print(f\"Skipping {file}: data for {patient_id} month {month} is already in {output_file}.\")\n",
    "            continue\n",
    "\n",
    "        # Add to the global DataFrame\n",
    "        df.to_csv(output_file, mode='a', header=not os.path.exists(output_file), index=False)\n",
    "\n",
    "        print(f\"Added {file} to {output_file}.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"***** Error: Failed to process {file}. Reason: {str(e)} *****\")\n",
    "\n",
    "print(\"Merging process completed.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
