{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First analysis: calculation of the FuncUseRatio\n",
    "Author: Marion Granier  \n",
    "Date: 2025-03-17 \n",
    "  \n",
    "This script uses part of Victor Fernando Lopes De Souza's script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the autoreload extension\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set extension to autoreload all modules every time before executing the Python code\n",
    "%autoreload 2\n",
    "\n",
    "# Importing the necessary libraries\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['agg.path.chunksize'] = 10000\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "\n",
    "notebook_dir = os.getcwd()\n",
    "sys.path.append(os.path.join(notebook_dir,\"..\", \"sources\"))\n",
    "\n",
    "import handle_data, functional_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if all csv files are present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>folder_name</th>\n",
       "      <th>is_patient</th>\n",
       "      <th>parent_folder</th>\n",
       "      <th>paretic_side</th>\n",
       "      <th>start_day</th>\n",
       "      <th>end_day</th>\n",
       "      <th>start_month</th>\n",
       "      <th>end_month</th>\n",
       "      <th>start_year</th>\n",
       "      <th>end_year</th>\n",
       "      <th>age</th>\n",
       "      <th>FMScore</th>\n",
       "      <th>freq</th>\n",
       "      <th>time_stroke</th>\n",
       "      <th>laterality</th>\n",
       "      <th>barthel</th>\n",
       "      <th>bbt_paretic</th>\n",
       "      <th>bbt_non_paretic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C1P20_M1</td>\n",
       "      <td>True</td>\n",
       "      <td>data_actimetry</td>\n",
       "      <td>right</td>\n",
       "      <td>29</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024</td>\n",
       "      <td>34</td>\n",
       "      <td>56</td>\n",
       "      <td>50</td>\n",
       "      <td>115.0</td>\n",
       "      <td>right</td>\n",
       "      <td>100</td>\n",
       "      <td>42</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C1P30_M1</td>\n",
       "      <td>True</td>\n",
       "      <td>data_actimetry</td>\n",
       "      <td>right</td>\n",
       "      <td>29</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024</td>\n",
       "      <td>67</td>\n",
       "      <td>45</td>\n",
       "      <td>50</td>\n",
       "      <td>36.0</td>\n",
       "      <td>right</td>\n",
       "      <td>95</td>\n",
       "      <td>17</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C1P31_M1</td>\n",
       "      <td>True</td>\n",
       "      <td>data_actimetry</td>\n",
       "      <td>left</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2025</td>\n",
       "      <td>2025</td>\n",
       "      <td>75</td>\n",
       "      <td>49</td>\n",
       "      <td>50</td>\n",
       "      <td>123.0</td>\n",
       "      <td>right</td>\n",
       "      <td>80</td>\n",
       "      <td>35</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C1P32_M1</td>\n",
       "      <td>True</td>\n",
       "      <td>data_actimetry</td>\n",
       "      <td>right</td>\n",
       "      <td>29</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024</td>\n",
       "      <td>78</td>\n",
       "      <td>45</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>right</td>\n",
       "      <td>90</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C1P33_M1</td>\n",
       "      <td>True</td>\n",
       "      <td>data_actimetry</td>\n",
       "      <td>left</td>\n",
       "      <td>29</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024</td>\n",
       "      <td>81</td>\n",
       "      <td>54</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>right</td>\n",
       "      <td>85</td>\n",
       "      <td>18</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  folder_name  is_patient   parent_folder paretic_side  start_day  end_day  \\\n",
       "0    C1P20_M1        True  data_actimetry        right         29        7   \n",
       "1    C1P30_M1        True  data_actimetry        right         29        7   \n",
       "2    C1P31_M1        True  data_actimetry         left         10       18   \n",
       "3    C1P32_M1        True  data_actimetry        right         29        7   \n",
       "4    C1P33_M1        True  data_actimetry         left         29        7   \n",
       "\n",
       "   start_month  end_month  start_year  end_year  age  FMScore  freq  \\\n",
       "0           11         12        2024      2024   34       56    50   \n",
       "1           11         12        2024      2024   67       45    50   \n",
       "2            1          1        2025      2025   75       49    50   \n",
       "3           11         12        2024      2024   78       45    50   \n",
       "4           11         12        2024      2024   81       54    50   \n",
       "\n",
       "   time_stroke laterality  barthel  bbt_paretic  bbt_non_paretic  \n",
       "0        115.0      right      100           42               62  \n",
       "1         36.0      right       95           17               46  \n",
       "2        123.0      right       80           35               52  \n",
       "3          NaN      right       90           20               50  \n",
       "4          NaN      right       85           18               38  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "participants_info = pd.read_csv('../data/participants_1.csv', sep=';')\n",
    "participants_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C1P20', 'C1P30', 'C1P31', 'C1P32', 'C1P33']\n",
      "***** Missing file: C1P20_M4 *****\n",
      "***** Missing file: C1P20_M5 *****\n",
      "***** Missing file: C1P20_M6 *****\n",
      "***** Missing file: C1P30_M4 *****\n",
      "***** Missing file: C1P30_M5 *****\n",
      "***** Missing file: C1P30_M6 *****\n",
      "***** Missing file: C1P31_M3 *****\n",
      "***** Missing file: C1P31_M4 *****\n",
      "***** Missing file: C1P31_M5 *****\n",
      "***** Missing file: C1P31_M6 *****\n",
      "***** Missing file: C1P32_M4 *****\n",
      "***** Missing file: C1P32_M5 *****\n",
      "***** Missing file: C1P32_M6 *****\n",
      "***** Missing file: C1P33_M4 *****\n",
      "***** Missing file: C1P33_M5 *****\n",
      "***** Missing file: C1P33_M6 *****\n"
     ]
    }
   ],
   "source": [
    "# Definition of the base path and the list of patients\n",
    "base_path = \"../data/data_actimetry\"\n",
    "patients = participants_info['folder_name'].str.split('_M').str[0].tolist()\n",
    "# patients = [\"C1P20\", \"C1P30\", \"C1P31\", \"C1P32\", \"C1P33\"]\n",
    "print(patients)\n",
    "months = [f\"M{i}\" for i in range(1, 7)]  # M1 to M6\n",
    "\n",
    "# Function to check if the files are present\n",
    "def check_files():\n",
    "    \"\"\"\n",
    "    Check if the files are present in the base path for each patient and each month.\n",
    "    \"\"\"\n",
    "    for patient in patients:\n",
    "        for month in months:\n",
    "            folder_name = f\"{patient}_{month}\"\n",
    "            folder_path = os.path.join(base_path, folder_name)\n",
    "            \n",
    "            if not os.path.exists(folder_path):\n",
    "                print(f\"***** Missing file: {folder_name} *****\")\n",
    "                continue\n",
    "            \n",
    "            left_file = os.path.join(folder_path, \"left.csv\")\n",
    "            right_file = os.path.join(folder_path, \"right.csv\")\n",
    "            \n",
    "            missing_files = []\n",
    "            if not os.path.isfile(left_file):\n",
    "                missing_files.append(\"left.csv\")\n",
    "            if not os.path.isfile(right_file):\n",
    "                missing_files.append(\"right.csv\")\n",
    "            \n",
    "            if missing_files:\n",
    "                print(f\"***** Missing files in {folder_name} : {', '.join(missing_files)} *****\")\n",
    "#            else:\n",
    "#                print(f\"All files are present in {folder_name}.\")\n",
    "\n",
    "check_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FuncUseRatioPerDay for all patients and all months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "Processing C1P20_M1 for month 1\n",
      "-----\n",
      "Processing C1P30_M1 for month 1\n",
      "-----\n",
      "Processing C1P31_M1 for month 1\n",
      "-----\n",
      "Processing C1P32_M1 for month 1\n",
      "-----\n",
      "Processing C1P33_M1 for month 1\n",
      "-----\n",
      "Processing C1P20_M2 for month 2\n",
      "-----\n",
      "Processing C1P30_M2 for month 2\n",
      "-----\n",
      "Processing C1P31_M2 for month 2\n",
      "-----\n",
      "Processing C1P32_M2 for month 2\n",
      "-----\n",
      "Processing C1P33_M2 for month 2\n",
      "Processing complete. Results saved to 'results_FuncUsePerDay_all_patients.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Resampling\n",
    "resampling_freq = 50 # Hz\n",
    "\n",
    "# Low pass filter\n",
    "filter_butter_cutoff = 1 # Hz\n",
    "\n",
    "# Windowing\n",
    "### VOIR SI ON LA PASSE A 2 SECONDES COMME LEUENBERGER ET GAEL ONT FAIT\n",
    "seconds_per_window = 0.5 # s \n",
    "\n",
    "# To calculate the jerk ratio we ignore the moments where one arm is not moving\n",
    "treshold_removal_JR = 0.01 # m/s^3\n",
    "\n",
    "def get_functional_uses_per_day(folder_name, month):\n",
    "    \"\"\"\n",
    "    Get functional use counts per day for the given patient and month.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # get data\n",
    "        time_index, acceleration_xyzn, is_patient, FM = handle_data.extract_data(folder_name, filter_butter_cutoff=filter_butter_cutoff, resampling_freq=resampling_freq, month=month)\n",
    "        \n",
    "        # convert time index to seconds\n",
    "        time_index_values = (time_index.values - np.datetime64('1970-01-01T00:00:00')) / np.timedelta64(1, 's')\n",
    "        \n",
    "        # partition data\n",
    "        windows_small, time_indexes_small = handle_data.partition(acceleration_xyzn, time_index_values, seconds_per_window=seconds_per_window)\n",
    "\n",
    "        # get angles\n",
    "        alphas = functional_metrics.get_alphas(windows_small[:, :, :, 1], windows_small[:, :, :, 3])\n",
    "\n",
    "        # get if window contains a functional movement for different (symmetric) angle thresholds (30)\n",
    "        test_range = [30]\n",
    "        is_functional = {i: functional_metrics.test_functional(alphas=alphas, treshold_symregion_degrees=i, treshold_amp_degrees=30) for i in test_range}\n",
    "        \n",
    "        # Get functional count per day\n",
    "        functional_count_per_day = functional_metrics.get_functional_count_per_day(is_functional[30], time_indexes_small)\n",
    "        functional_uses_per_day_df = pd.DataFrame(functional_count_per_day)\n",
    "\n",
    "        # Add patient info to the dataframe\n",
    "        ID = folder_name.split('_')[0]\n",
    "        functional_uses_per_day_df.insert(0, 'ID', ID)\n",
    "        functional_uses_per_day_df.insert(1, 'month', month)\n",
    "        functional_uses_per_day_df.insert(2, 'day', range(1, functional_uses_per_day_df.shape[0] + 1))\n",
    "        functional_uses_per_day_df.columns = ['ID', 'month', 'day', 'FuncUse_non_paretic_day', 'FuncUse_paretic_day']\n",
    "        functional_uses_per_day_df['FuncUseRatio_day'] = functional_uses_per_day_df['FuncUse_paretic_day'] / (functional_uses_per_day_df['FuncUse_paretic_day'] + functional_uses_per_day_df['FuncUse_non_paretic_day'])\n",
    "\n",
    "        return functional_uses_per_day_df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing functional uses per day for {folder_name} in month {month}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Define months you want to process\n",
    "months = [1, 2]\n",
    "\n",
    "# Initialize an empty list to store all daily results\n",
    "all_daily_results = []\n",
    "\n",
    "# Loop over each month\n",
    "for month in months:\n",
    "    # Load participants info for the current month\n",
    "    participants_info = pd.read_csv(f'../data/participants_{month}.csv', sep=';')\n",
    "    \n",
    "    # Process each participant in the current month\n",
    "    for _, row in participants_info.iterrows():\n",
    "        folder_name = row['folder_name']\n",
    "        print(f'-----\\nProcessing {folder_name} for month {month}')\n",
    "        try:\n",
    "            # Get the functional uses per day for this folder_name and month\n",
    "            daily_result = get_functional_uses_per_day(folder_name, month)\n",
    "            \n",
    "            # If result is not None, append it to the global list\n",
    "            if daily_result is not None:\n",
    "                all_daily_results.append(daily_result)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f'Error processing {folder_name}: {e}')\n",
    "\n",
    "# Concatenate all daily results into a single DataFrame\n",
    "all_daily_results_df = pd.concat(all_daily_results, axis=0)\n",
    "\n",
    "# Sort the dataframe by patient (ID), then by month, and finally by day\n",
    "all_daily_results_df = all_daily_results_df.sort_values(by=['ID', 'month', 'day']).reset_index(drop=True)\n",
    "\n",
    "# Save the final daily results to a CSV file\n",
    "all_daily_results_df.to_csv('../results/results_FuncUsePerDay_all_patients.csv', index=False)\n",
    "\n",
    "print(\"Processing complete. Results saved to 'results_FuncUsePerDay_all_patients.csv'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FuncUseRatio per month for all patients and all months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resampling\n",
    "resampling_freq = 50 # Hz\n",
    "\n",
    "# Low pass filter\n",
    "filter_butter_cutoff = 1 # Hz\n",
    "\n",
    "# Windowing\n",
    "### VOIR SI ON LA PASSE A 2 SECONDES COMME LEUENBERGER ET GAEL ONT FAIT\n",
    "seconds_per_window = 0.5 # s \n",
    "\n",
    "# To calculate the jerk ratio we ignore the moments where one arm is not moving\n",
    "treshold_removal_JR = 0.01 # m/s^3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "Processing C1P20_M1\n",
      "-----\n",
      "Processing C1P30_M1\n",
      "-----\n",
      "Processing C1P31_M1\n",
      "-----\n",
      "Processing C1P32_M1\n",
      "-----\n",
      "Processing C1P33_M1\n",
      "-----\n",
      "Processing C1P20_M2\n",
      "-----\n",
      "Processing C1P30_M2\n",
      "-----\n",
      "Processing C1P31_M2\n",
      "-----\n",
      "Processing C1P32_M2\n",
      "-----\n",
      "Processing C1P33_M2\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'ID'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2456\\3713068399.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[0mall_results_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'index'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'ID'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[1;31m# Sort the dataframe by patient (ID), then by month, and finally by day\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m \u001b[0mall_results_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mall_results_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ID'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'month'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;31m# Reset the index of the results DataFrame for final output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[1;31m# all_results_df.reset_index(drop=False, inplace=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Factory\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[0m\n\u001b[0;32m   7168\u001b[0m                 \u001b[1;33mf\"\u001b[0m\u001b[1;33mLength of ascending (\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mascending\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\"\u001b[0m  \u001b[1;31m# type: ignore[arg-type]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7169\u001b[0m                 \u001b[1;33mf\"\u001b[0m\u001b[1;33m != length of by (\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7170\u001b[0m             \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7171\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 7172\u001b[1;33m             \u001b[0mkeys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   7173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7174\u001b[0m             \u001b[1;31m# need to rewrap columns in Series to apply key function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7175\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Factory\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1907\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mother_axes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1908\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_level_reference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1909\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1910\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1911\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1912\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1913\u001b[0m         \u001b[1;31m# Check for duplicates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1914\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'ID'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_participant_metrics(folder_name, month):\n",
    "    \"\"\" \n",
    "    folder_name: name of the folder containing the actimetric files \n",
    "    month: a vector containing the months to be analyzed\n",
    "\n",
    "    return: An overall dataframe with all the variables of interest for each patient and each month\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # get data\n",
    "        time_index, acceleration_xyzn, is_patient, FM = handle_data.extract_data(folder_name, filter_butter_cutoff=filter_butter_cutoff, resampling_freq=resampling_freq, month=month)\n",
    "        # convert time index to seconds\n",
    "        time_index_values = (time_index.values - np.datetime64('1970-01-01T00:00:00')) / np.timedelta64(1, 's')\n",
    "        # partition data\n",
    "        windows_small, time_indexes_small = handle_data.partition(acceleration_xyzn, time_index_values, seconds_per_window=seconds_per_window)\n",
    "\n",
    "        # get angles\n",
    "        alphas = functional_metrics.get_alphas(windows_small[:, :, :, 1], windows_small[:, :, :, 3])\n",
    "\n",
    "        # get if window contains a functional movement for different (symmetric) angle thresholds (30)\n",
    "        test_range = [30]\n",
    "        is_functional = {i: functional_metrics.test_functional(alphas=alphas, treshold_symregion_degrees=i, treshold_amp_degrees=30) for i in test_range}\n",
    "\n",
    "        # get functional use counts\n",
    "        functional_uses = {i: is_functional[i].sum(axis=0) for i in test_range}\n",
    "        functional_uses_df = pd.DataFrame(functional_uses).T\n",
    "        functional_uses_df.columns = ['functional_non_paretic', 'functional_paretic']\n",
    "        functional_uses_df['functional_ratio'] = functional_metrics.get_ratio(functional_uses_df['functional_non_paretic'], functional_uses_df['functional_paretic'])\n",
    "\n",
    "        # get use hours (considering 30 degrees as threshold)\n",
    "        use_hours = functional_metrics.get_use_hours(is_functional[30], time_indexes_small)\n",
    "        # get use hours ratio\n",
    "        use_hours_ratio = functional_metrics.get_ratio(use_hours[0], use_hours[1])\n",
    "\n",
    "        # save results\n",
    "        patient_id = folder_name.split('_')[0]\n",
    "\n",
    "        # Return results for the current patient for the specified month\n",
    "        results_global = pd.DataFrame({'month': month,\n",
    "                                      'FuncUse_non_paretic_month': functional_uses_df.iloc[0, 0],\n",
    "                                      'FuncUse_paretic_month': functional_uses_df.iloc[0, 1],\n",
    "                                      'FuncUserRatio_month': functional_uses_df.iloc[0, 1] / (functional_uses_df.iloc[0, 1] + functional_uses_df.iloc[0, 0]),\n",
    "                                      'UseHours_non_paretic_month': use_hours[0],\n",
    "                                      'UseHours_paretic_month': use_hours[1],\n",
    "                                      'UseHoursRatio_month': use_hours_ratio / 2}, index=[patient_id])\n",
    "\n",
    "        return results_global\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {folder_name} for month {month}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Define months you want to process\n",
    "months = [1, 2]\n",
    "\n",
    "# Initialize an empty DataFrame to store all results\n",
    "all_results = []\n",
    "\n",
    "# Loop over each month\n",
    "for month in months:\n",
    "    # Load participants info for the current month\n",
    "    participants_info = pd.read_csv(f'../data/participants_{month}.csv', sep=';')\n",
    "    \n",
    "    # Process each participant in the current month\n",
    "    for _, row in participants_info.iterrows():\n",
    "        folder_name = row['folder_name']\n",
    "        print(f'-----\\nProcessing {folder_name}')\n",
    "        try:\n",
    "            # Get participant metrics for this folder_name and month\n",
    "#            result = functional_metrics.get_participant_metrics(folder_name, month)\n",
    "            result = get_participant_metrics(folder_name, month)\n",
    "            \n",
    "            # If result is not None, append it to the global results list\n",
    "            if result is not None:\n",
    "                all_results.append(result)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f'Error processing {folder_name}: {e}')\n",
    "\n",
    "# Concatenate all the results by patient\n",
    "all_results_df = pd.concat(all_results, axis=0)\n",
    "\n",
    "all_results_df = pd.read_csv('../results/results_FuncUse_all_patients.csv')\n",
    "all_results_df.rename(columns={all_results_df.columns[0]: 'ID'}, inplace=True)\n",
    "\n",
    "# Sort the dataframe by patient (ID), then by month, and finally by day\n",
    "all_results_df = all_results_df.sort_values(by=['ID', 'month']).reset_index(drop=True)\n",
    "\n",
    "# Save the final results to a CSV file\n",
    "all_results_df.to_csv('../results/results_FuncUse_all_patients.csv', index=False)\n",
    "\n",
    "print(\"Processing complete. Results saved to 'results_FuncUse_all_patients.csv'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For a single patient and a single month\n",
    "\n",
    "### Enter the data information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patient's code (CXPXX)\n",
    "ID = \"C1P33\"\n",
    "\n",
    "# Number of the record (X in range of 1 to 6)\n",
    "month = \"1\"\n",
    "\n",
    "# Resampling\n",
    "resampling_freq = 50 # Hz\n",
    "\n",
    "# Low pass filter\n",
    "filter_butter_cutoff = 1 # Hz\n",
    "\n",
    "# Windowing\n",
    "seconds_per_window = 0.5 # s\n",
    "\n",
    "# To calculate the jerk ratio we ignore the moments where one arm is not moving\n",
    "treshold_removal_JR = 0.01 # m/s^3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FileName = ID + \"_M\" + month\n",
    "FileName\n",
    "\n",
    "# Load the data\n",
    "time_index, acceleration_xyzn, is_patient, FM = handle_data.extract_data(FileName, filter_butter_cutoff=filter_butter_cutoff, resampling_freq=resampling_freq, month=month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32399681, 2, 4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acceleration_xyzn.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_index_values = (time_index.values - np.datetime64('1970-01-01T00:00:00')) / np.timedelta64(1, 's')\n",
    "windows_small, time_indexes_small = handle_data.partition(acceleration_xyzn, time_index_values, seconds_per_window=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get jerk\n",
    "# jerk = functional_metrics.get_jerk(acceleration_xyzn, time_index_values)\n",
    "# get jerk ratio\n",
    "# jerk_ratio = functional_metrics.get_jerk_ratio(jerk, treshold_removal=treshold_removal_JR)\n",
    "# get jerk ratio mean\n",
    "# jerk_ratio_mean = np.mean(jerk_ratio)\n",
    "\n",
    "# get angles\n",
    "alphas = functional_metrics.get_alphas(windows_small[:, :, :, 1], windows_small[:, :, :, 3])\n",
    "\n",
    "# get if window contains a functional movement for different (symmetric) angle thresholds (10, 20, ..., 80)\n",
    "test_range = range(10, 90, 10)\n",
    "is_functional = {i : functional_metrics.test_functional(alphas=alphas, treshold_symregion_degrees=i, treshold_amp_degrees=30) for i in test_range}\n",
    "\n",
    "# get functional use counts\n",
    "functional_uses = {i : is_functional[i].sum(axis=0) for i in test_range}\n",
    "functional_uses_df = pd.DataFrame(functional_uses).T\n",
    "functional_uses_df.columns = ['non_paretic', 'paretic']\n",
    "\n",
    "# get use hours (considering 30 degrees as threshold)\n",
    "use_hours = functional_metrics.get_use_hours(is_functional[30], time_indexes_small)\n",
    "use_hours\n",
    "# get use hours ratio\n",
    "use_hours_ratio = functional_metrics.get_ratio(use_hours[0], use_hours[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FuncUse per month (one patient, one month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe with the results\n",
    "results_global = pd.DataFrame({'month' : month,\n",
    "                        'FuncUse_non_paretic_month' : functional_uses_df.iloc[2, 0],\n",
    "                        'FuncUse_paretic_month' : functional_uses_df.iloc[2, 1],  \n",
    "                        'FuncUserRatio_month' : functional_uses_df.iloc[2, 1] / (functional_uses_df.iloc[2, 1] + functional_uses_df.iloc[2, 0]),\n",
    "                        'UseHours_non_paretic_month' : use_hours[0],\n",
    "                        'UseHours_paretic_month' : use_hours[1],\n",
    "                        'UseHoursRatio_month' : use_hours_ratio / 2}, index=[ID])\n",
    "results_global\n",
    "\n",
    "# save the results per month\n",
    "results_global.to_csv('../results/results_FuncUse' + ID + '_M' + month + '.csv', index_label=\"ID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate individual reports to make a global report of all patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added results_C1P30_M1.csv to ../results/all_global_results.csv.\n",
      "Added results_C1P30_M2.csv to ../results/all_global_results.csv.\n",
      "Added results_C1P30_M3.csv to ../results/all_global_results.csv.\n",
      "Added results_C1P31_M1.csv to ../results/all_global_results.csv.\n",
      "Added results_C1P31_M2.csv to ../results/all_global_results.csv.\n",
      "Added results_C1P32_M1.csv to ../results/all_global_results.csv.\n",
      "Added results_C1P32_M2.csv to ../results/all_global_results.csv.\n",
      "Added results_C1P32_M3.csv to ../results/all_global_results.csv.\n",
      "Added results_C1P33_M1.csv to ../results/all_global_results.csv.\n",
      "Added results_C1P33_M2.csv to ../results/all_global_results.csv.\n",
      "Added results_C1P33_M3.csv to ../results/all_global_results.csv.\n",
      "Merging process completed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Define the folder path and the output file\n",
    "folder_path = '../results/'\n",
    "output_file = os.path.join(folder_path, 'all_global_results.csv')\n",
    "\n",
    "# Identify the pattern of the files\n",
    "file_pattern = re.compile(r'results_C(\\w+)_M(\\d+)\\.csv')\n",
    "\n",
    "# Recover the list of files\n",
    "csv_files = [f for f in os.listdir(folder_path) if file_pattern.match(f)]\n",
    "\n",
    "# Sort the files by patient ID and month\n",
    "csv_files.sort(key=lambda x: (file_pattern.match(x).group(1), int(file_pattern.match(x).group(2))))\n",
    "\n",
    "# Load the first file to get the columns\n",
    "first_file = os.path.join(folder_path, csv_files[0])\n",
    "df_example = pd.read_csv(first_file)\n",
    "columns = df_example.columns.tolist()\n",
    "\n",
    "# Load the global DataFrame if it exists\n",
    "if os.path.exists(output_file):\n",
    "    global_df = pd.read_csv(output_file)\n",
    "else:\n",
    "    global_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "# Traits each file\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "\n",
    "    try:\n",
    "        # read the file\n",
    "        df = pd.read_csv(file_path, skiprows=1, header=None, names=columns)\n",
    "        if df.empty:\n",
    "            print(f\"***** Warning: {file} is empty and will be skipped. *****\")\n",
    "            continue\n",
    "\n",
    "        # Recover the patient ID and month\n",
    "        match = file_pattern.match(file)\n",
    "        patient_id, month = match.groups()\n",
    "        month = int(month)\n",
    "\n",
    "        # Check if the data is already in the global\n",
    "        if not global_df.empty and ((global_df['ID'] == patient_id) & (global_df['month'] == month)).any():\n",
    "            print(f\"Skipping {file}: data for {patient_id} month {month} is already in {output_file}.\")\n",
    "            continue\n",
    "\n",
    "        # Add to the global DataFrame\n",
    "        df.to_csv(output_file, mode='a', header=not os.path.exists(output_file), index=False)\n",
    "\n",
    "        print(f\"Added {file} to {output_file}.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"***** Error: Failed to process {file}. Reason: {str(e)} *****\")\n",
    "\n",
    "print(\"Merging process completed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FuncUsePerDay (one patient, one month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ID month  day  FuncUse_non_paretic_day  FuncUse_paretic_day  \\\n",
      "0  C1P33     1    1                    201.0                 49.0   \n",
      "1  C1P33     1    2                    149.0                 34.0   \n",
      "2  C1P33     1    3                    156.0                 46.0   \n",
      "3  C1P33     1    4                    187.0                 31.0   \n",
      "4  C1P33     1    5                    197.0                 22.0   \n",
      "5  C1P33     1    6                    211.0                 33.0   \n",
      "6  C1P33     1    7                    196.0                 29.0   \n",
      "7  C1P33     1    8                      1.0                  1.0   \n",
      "\n",
      "   FuncUseRatio_day  \n",
      "0          0.196000  \n",
      "1          0.185792  \n",
      "2          0.227723  \n",
      "3          0.142202  \n",
      "4          0.100457  \n",
      "5          0.135246  \n",
      "6          0.128889  \n",
      "7          0.500000  \n"
     ]
    }
   ],
   "source": [
    "# get functional count per day\n",
    "functional_count_per_day = functional_metrics.get_functional_count_per_day(is_functional[30], time_indexes_small)\n",
    "functional_count_per_day\n",
    "functional_uses_per_day_df = pd.DataFrame(functional_count_per_day)\n",
    "\n",
    "# create the dataframe of FuncUse per day for the patient\n",
    "functional_uses_per_day_df.insert(0, 'ID', ID)\n",
    "functional_uses_per_day_df.insert(1, 'month', month)\n",
    "functional_uses_per_day_df.insert(2, 'day', range(1, functional_uses_per_day_df.shape[0] + 1))\n",
    "functional_uses_per_day_df.columns = ['ID', 'month', 'day', 'FuncUse_non_paretic_day', 'FuncUse_paretic_day']\n",
    "functional_uses_per_day_df['FuncUseRatio_day'] = functional_uses_per_day_df['FuncUse_paretic_day'] / (functional_uses_per_day_df['FuncUse_paretic_day'] + functional_uses_per_day_df['FuncUse_non_paretic_day'])\n",
    "print(functional_uses_per_day_df)\n",
    "\n",
    "# save the results per day\n",
    "functional_uses_per_day_df.to_csv('../results/results_FuncUsePerDay_' + ID + '_M' + month + '.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
